{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d4c5c9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-06T01:06:48.147581Z",
     "iopub.status.busy": "2023-05-06T01:06:48.147139Z",
     "iopub.status.idle": "2023-05-06T01:06:48.169229Z",
     "shell.execute_reply": "2023-05-06T01:06:48.168141Z"
    },
    "papermill": {
     "duration": 0.033036,
     "end_time": "2023-05-06T01:06:48.171321",
     "exception": false,
     "start_time": "2023-05-06T01:06:48.138285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c3afe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T01:06:48.183524Z",
     "iopub.status.busy": "2023-05-06T01:06:48.182768Z",
     "iopub.status.idle": "2023-05-06T01:07:00.169772Z",
     "shell.execute_reply": "2023-05-06T01:07:00.168516Z"
    },
    "papermill": {
     "duration": 11.996122,
     "end_time": "2023-05-06T01:07:00.172551",
     "exception": false,
     "start_time": "2023-05-06T01:06:48.176429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e4df47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T01:07:00.185079Z",
     "iopub.status.busy": "2023-05-06T01:07:00.184681Z",
     "iopub.status.idle": "2023-05-06T01:07:05.171636Z",
     "shell.execute_reply": "2023-05-06T01:07:05.170484Z"
    },
    "papermill": {
     "duration": 4.995699,
     "end_time": "2023-05-06T01:07:05.173720",
     "exception": false,
     "start_time": "2023-05-06T01:07:00.178021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''All the required libraries for the project'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import random_split\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "# import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "pd.set_option('display.max_columns', 20)\n",
    "\n",
    "use_gpu = True\n",
    "device = torch.device(\"cuda\" if (use_gpu and torch.cuda.is_available()) else \"cpu\")\n",
    "print(f\"Using Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a5b49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T01:07:05.186418Z",
     "iopub.status.busy": "2023-05-06T01:07:05.185880Z",
     "iopub.status.idle": "2023-05-06T01:07:05.191056Z",
     "shell.execute_reply": "2023-05-06T01:07:05.190027Z"
    },
    "papermill": {
     "duration": 0.013952,
     "end_time": "2023-05-06T01:07:05.193145",
     "exception": false,
     "start_time": "2023-05-06T01:07:05.179193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "class Hyperparameters:\n",
    "    '''Hyperparameters for the project'''\n",
    "    _DATA_DIR = 'data/fer20131.csv'\n",
    "    _BATCH_SIZE = 64\n",
    "    _DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96da44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "params = {\n",
    "    'shuffle': True,\n",
    "    'num_workers': 1,\n",
    "    'lr': 1e-5,\n",
    "    'weight_decay': 1e-5,\n",
    "    'num_epochs': 200,\n",
    "    'num_classes': 7,\n",
    "    'print_every': 100,\n",
    "    'save_path': 'models/best_model.pt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49a5bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses and results\n",
    "def plot_results(results):\n",
    "    train_losses, train_accuracies, val_losses, val_accuracies = results\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    ax[0].plot(train_losses, '*-', label='Training Loss')\n",
    "    ax[0].plot(val_losses, '*-', label='Validation Loss')\n",
    "    ax[0].set_title('Losses vs Epochs', fontsize=16)\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].legend()\n",
    "\n",
    "    \n",
    "    ax[1].plot(train_accuracies, '*-', label='Training Accuracy')\n",
    "    ax[1].plot(val_accuracies, '*-', label='Validation Accuracy')\n",
    "    ax[1].set_title('Accuracy vs Epochs', fontsize=16)\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].legend()\n",
    "    \n",
    "    plt.suptitle('Training and Validation Results', y=0.95, fontsize=20)\n",
    "        \n",
    "    # # Save as .png file\n",
    "    # plt.savefig('plots/plot.png')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd1ef0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T01:07:05.205786Z",
     "iopub.status.busy": "2023-05-06T01:07:05.204853Z",
     "iopub.status.idle": "2023-05-06T01:07:05.245162Z",
     "shell.execute_reply": "2023-05-06T01:07:05.244276Z"
    },
    "papermill": {
     "duration": 0.048905,
     "end_time": "2023-05-06T01:07:05.247194",
     "exception": false,
     "start_time": "2023-05-06T01:07:05.198289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset class\n",
    "\n",
    "\n",
    "class FacialEmotionRecognitionDataset(Dataset):\n",
    "    '''This is the dataset class for the Facial Emotion Recognition Dataset\n",
    "        Args:\n",
    "            data_dir: path to the dataset csv file\n",
    "            transform: transform to be applied to the dataset\n",
    "            debug: whether to run in debug mode or not\n",
    "    '''\n",
    "\n",
    "    # constructor\n",
    "    def __init__(self, data_dir, split='train', transform=None, debug=False):\n",
    "        train_tfms, val_tfms = get_transformations()\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        if self.transform is None:\n",
    "            self.transform = train_tfms if split == 'train' else val_tfms\n",
    "        self.tensor_transform = transforms.ToTensor()\n",
    "        self.emotions = {\n",
    "            0: 'Angry',\n",
    "            1: 'Disgust',\n",
    "            2: 'Fear',\n",
    "            3: 'Happy',\n",
    "            4: 'Sad',\n",
    "            5: 'Surprise',\n",
    "            6: 'Neutral'\n",
    "        }\n",
    "        # read the dataset\n",
    "        dataset = pd.read_csv(data_dir)  # read the dataset\n",
    "        if self.split == 'train':\n",
    "            dataset = dataset.loc[dataset.Usage.isin(\n",
    "                ['Training', 'PublicTest'])]\n",
    "            dataset.reset_index(drop=True, inplace=True)\n",
    "            dataset = dataset.drop('Usage', axis=1)\n",
    "        elif self.split == 'test':\n",
    "            dataset = dataset.loc[dataset.Usage.isin(['PrivateTest'])]\n",
    "            dataset.reset_index(drop=True, inplace=True)\n",
    "            dataset = dataset.drop('Usage', axis=1)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid split type: must be either train or test\")\n",
    "\n",
    "        if debug:\n",
    "            print(\"-\"*100)\n",
    "            print(dataset.info())\n",
    "            print(\"-\"*100)\n",
    "            print(dataset.head())\n",
    "            print(\"-\"*100)\n",
    "\n",
    "#         pixels_values = []  # for storing pixel values\n",
    "#         for pix in dataset.pixels:\n",
    "#             values = [int(i) for i in pix.split()]\n",
    "#             pixels_values.append(values)\n",
    "\n",
    "#         pixels_values = np.array(pixels_values)\n",
    "        pixels_values = [[int(i) for i in pix.split()] for pix in dataset.pixels]   # for storing pixel values \n",
    "        pixels_values = np.array(pixels_values)\n",
    "        # rescaling pixel values\n",
    "        pixels_values = pixels_values/255.0\n",
    "        dataset.drop(columns=['pixels'], axis=1, inplace=True)\n",
    "        self.pix_cols = []  # for keeping track of column names\n",
    "\n",
    "        # add each pixel value as a column\n",
    "        for i in range(pixels_values.shape[1]):\n",
    "            self.pix_cols.append(f'pixel_{i}')\n",
    "            dataset[f'pixel_{i}'] = pixels_values[:, i]\n",
    "\n",
    "        if debug:\n",
    "            print(\"-\"*100)\n",
    "            print(\"| Refined Dataset |\")\n",
    "            print(\"-\"*100)\n",
    "            print(dataset.head())\n",
    "            print(\"-\"*100)\n",
    "\n",
    "        self.df = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = int(row['emotion'])\n",
    "        img = np.copy(row[self.pix_cols].values.reshape(48, 48))\n",
    "        img.setflags(write=True)\n",
    "\n",
    "        if self.transform:\n",
    "            img = Image.fromarray(img)\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = self.tensor_transform(img)\n",
    "\n",
    "        return img, img_id\n",
    "\n",
    "    def plot_distribution(self, path=None):\n",
    "        '''This function plots the distribution of the dataset'''\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(x='emotion', data=self.df)\n",
    "        plt.title(f\"Emotion Distribution: {self.split.upper()} Dataset\", fontsize=18)\n",
    "        plt.xticks(ticks=range(0, 7), labels=[\n",
    "                   self.emotions[i] for i in range(0, 7)], )\n",
    "        if path:\n",
    "            plt.savefig(path)\n",
    "        plt.show()\n",
    "\n",
    "# transformations\n",
    "\n",
    "\n",
    "def get_transformations():\n",
    "    '''\n",
    "        Return transformations to be applied.\n",
    "        Input:\n",
    "            None\n",
    "        Output:\n",
    "            train_transforms: transformations to be applied on the training set\n",
    "            valid_transforms: transformations to be applied on the validation or test set\n",
    "    '''\n",
    "\n",
    "    train_trans = [\n",
    "        transforms.RandomCrop(48, padding=4, padding_mode='reflect'),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomAffine(\n",
    "            degrees=0,\n",
    "            translate=(0.01, 0.12),\n",
    "            shear=(0.01, 0.03),\n",
    "        ),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    "\n",
    "    val_trans = [\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    "\n",
    "    train_transforms = transforms.Compose(train_trans)\n",
    "    valid_transforms = transforms.Compose(val_trans)\n",
    "\n",
    "    return train_transforms, valid_transforms\n",
    "\n",
    "# get dataloaders\n",
    "\n",
    "\n",
    "def get_dataloaders(data_dir, val_size=0.2, batch_size=32, shuffle=True, transformations=None, debug=False):\n",
    "    '''This is function to load the dataset and returns the dataloaders\n",
    "        Args:\n",
    "            data_dir: path to the dataset\n",
    "            batch_size: batch size for the dataloader\n",
    "            num_workers: number of workers for the dataloader\n",
    "            shuffle: whether to shuffle the dataset or not\n",
    "            debug: whether to run in debug mode or not\n",
    "        Returns:\n",
    "            train_loader: dataloader for the training set\n",
    "            val_loader: dataloader for the validation set\n",
    "            test_loader: dataloader for the test set\n",
    "    '''\n",
    "    train_dataset = FacialEmotionRecognitionDataset(\n",
    "        data_dir=data_dir, split='train', debug=debug, transform=transformations)\n",
    "    test_dataset = FacialEmotionRecognitionDataset(\n",
    "        data_dir=data_dir, split='test', debug=debug, transform=transformations)\n",
    "    if debug:\n",
    "        train_dataset.plot_distribution()\n",
    "        test_dataset.plot_distribution()\n",
    "\n",
    "    val_len = int(val_size*len(train_dataset))\n",
    "    train_ds, val_ds = random_split(\n",
    "        train_dataset, [len(train_dataset)-val_len, val_len])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    if debug:\n",
    "        print(\"-\"*100)\n",
    "        print(f\"Train Dataset: {len(train_ds)} ({len(train_loader)} batches)\")\n",
    "        print(f\"Validation Dataset: {len(val_ds)} ({len(val_loader)} batches)\")\n",
    "        print(\n",
    "            f\"Test Dataset: {len(test_dataset)} ({len(test_loader)} batches)\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# show images\n",
    "\n",
    "\n",
    "def show_images(dataloader, title='Images'):\n",
    "    '''This function plots the images from the dataloader'''\n",
    "    fig, ax = plt.figure(figsize=(16, 8)), plt.axis(\"off\")\n",
    "    for images, _ in dataloader:\n",
    "        print('Images Shape:', images.shape)\n",
    "        plt.imshow(make_grid(images, nrow=8).permute(\n",
    "            (1, 2, 0)))  # move the channel dimension\n",
    "        break\n",
    "\n",
    "    plt.suptitle(f\"{title}\", y=0.92, fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "# accuracy calculation\n",
    "\n",
    "\n",
    "def get_accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "def get_model(num_classes, device, model_name='resnet34'):\n",
    "    '''This function returns the model to be used for training'''\n",
    "    if model_name == 'resnet18':\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        out_features = 512\n",
    "    elif model_name == 'resnet34':\n",
    "        model = models.resnet34(pretrained=True)\n",
    "        out_features = 512\n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        out_features = 2048\n",
    "    elif model_name == 'resnet101':\n",
    "        model = models.resnet101(pretrained=True)\n",
    "        out_features = 2048\n",
    "    elif model_name == 'densenet121':\n",
    "        model = models.densenet121(pretrained=True)\n",
    "        out_features = 1024\n",
    "    elif model_name == 'inception_v3':\n",
    "        model = models.inception_v3(pretrained=True)\n",
    "        out_features = 2048\n",
    "    else:\n",
    "        raise ValueError('Invalid Model Name: Options [resnet18, resnet34, resnet50, resnet101, dense121, inception_v3]')\n",
    "    \n",
    "    if model_name == 'densenet121':\n",
    "        # change the input layer to have 1 channel\n",
    "        model.features[0] = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(out_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.LogSoftmax(dim=1)   \n",
    "        )\n",
    "    elif model_name == 'inception_v3':\n",
    "        model.aux_logits = False\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(out_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "    else:\n",
    "        # add first layer to have input channels as 1\n",
    "        model.conv1 = nn.Conv2d(1, 64, kernel_size=7,\n",
    "                                stride=2, padding=3, bias=False)\n",
    "\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(out_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def confusion_matrix(labels, outputs):\n",
    "    labels = labels.cpu().numpy()\n",
    "    predicted = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    dimensions = 7 #len(np.unique(labels))\n",
    "    matrix = np.zeros((dimensions, dimensions))\n",
    "    for i in range(len(labels)):\n",
    "        matrix[labels[i], predicted[i]] += 1\n",
    "    return matrix\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    dimensions = 7\n",
    "    matrix = np.zeros((dimensions, dimensions))\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        acc = get_accuracy(outputs, labels)\n",
    "        labels = labels.cpu().numpy()\n",
    "        predicted = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        for i in range(len(labels)):\n",
    "            matrix[labels[i], predicted[i]] += 1\n",
    "        running_loss += loss.item()\n",
    "        running_acc += acc\n",
    "    \n",
    "    running_loss /= len(dataloader)\n",
    "    running_acc /= len(dataloader)\n",
    "    return running_loss, running_acc, matrix\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, params, debug=False):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, max_lr=params['lr'],\n",
    "                                                    epochs=params['num_epochs'],\n",
    "                                                    steps_per_epoch=len(train_loader))\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(params['num_epochs']):\n",
    "        print(f\"|--------- Epoch: {epoch+1:>{len(str(params['num_epochs']))}}/{params['num_epochs']} \" + \"-\"*110)\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        curr_len = 0\n",
    "        batch_id = 0\n",
    "        for images, labels in tqdm(train_loader, ascii=True, desc=f\"Epoch: {epoch+1:>{len(str(params['num_epochs']))}}/{params['num_epochs']}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            acc = get_accuracy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            running_loss += loss.item() * images.shape[0]\n",
    "            running_acc += acc\n",
    "            curr_len += images.shape[0]\n",
    "            batch_id += 1\n",
    "            if debug and batch_id % params['print_every'] == 0:\n",
    "                curr_loss = running_loss/curr_len\n",
    "                curr_acc = running_acc/batch_id\n",
    "                print('\\t\\t'+'-'*70)\n",
    "                print(\n",
    "                    f\"\\t\\t| Batch: {batch_id:>{len(str(len(train_loader)))}}/{len(train_loader)} | Training Loss: {curr_loss:.4f} | Training Accuracy: {curr_acc:.4f} |\")\n",
    "                print('\\t\\t'+'-'*70)\n",
    "\n",
    "        running_loss /= len(train_loader.dataset)\n",
    "        running_acc /= len(train_loader)\n",
    "        train_losses.append(running_loss)\n",
    "        train_accuracies.append(running_acc)\n",
    "        val_loss, val_acc, cm = evaluate_model(\n",
    "            model, val_loader, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        # Save the model only if the validation loss has decreased\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            model.load_state_dict(best_model_state)\n",
    "            torch.save(model.state_dict(), params['save_path'])\n",
    "\n",
    "        print('-'*120)\n",
    "        print(f\"Epoch: {epoch+1:>{len(str(params['num_epochs']))}}/{params['num_epochs']} | Training Loss: {running_loss:.4f} | Training Accuracy: {running_acc:.4f} | Validation Loss: {val_loss:.4f} | Validation Accuracy: {val_acc:.4f}\")\n",
    "        print('-'*120)\n",
    "        print(\"-\"*130 + '-|')\n",
    "\n",
    "        # Plot results every 5 epochs\n",
    "        if epoch != 0 and epoch+1 % 5 == 0:\n",
    "            plot_results((train_losses, train_accuracies, val_losses, val_accuracies))\n",
    "\n",
    "    return model, (train_losses, train_accuracies, val_losses, val_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad6b3c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T01:07:05.258199Z",
     "iopub.status.busy": "2023-05-06T01:07:05.257922Z",
     "iopub.status.idle": "2023-05-06T01:07:41.649078Z",
     "shell.execute_reply": "2023-05-06T01:07:41.647256Z"
    },
    "papermill": {
     "duration": 36.399479,
     "end_time": "2023-05-06T01:07:41.651653",
     "exception": false,
     "start_time": "2023-05-06T01:07:05.252174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = get_dataloaders(data_dir=Hyperparameters._DATA_DIR, batch_size= Hyperparameters._BATCH_SIZE, debug=Hyperparameters._DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1a1daa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T01:07:41.666693Z",
     "iopub.status.busy": "2023-05-06T01:07:41.666335Z",
     "iopub.status.idle": "2023-05-06T01:07:42.674856Z",
     "shell.execute_reply": "2023-05-06T01:07:42.673955Z"
    },
    "papermill": {
     "duration": 1.022155,
     "end_time": "2023-05-06T01:07:42.680499",
     "exception": false,
     "start_time": "2023-05-06T01:07:41.658344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_images(train_loader, 'Train Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6115dc78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T01:07:42.706407Z",
     "iopub.status.busy": "2023-05-06T01:07:42.706037Z",
     "iopub.status.idle": "2023-05-06T01:07:43.470236Z",
     "shell.execute_reply": "2023-05-06T01:07:43.469328Z"
    },
    "papermill": {
     "duration": 0.783301,
     "end_time": "2023-05-06T01:07:43.475898",
     "exception": false,
     "start_time": "2023-05-06T01:07:42.692597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_images(test_loader, 'Test Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392ea023",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T01:07:43.514847Z",
     "iopub.status.busy": "2023-05-06T01:07:43.513821Z",
     "iopub.status.idle": "2023-05-06T02:57:01.267570Z",
     "shell.execute_reply": "2023-05-06T02:57:01.264162Z"
    },
    "papermill": {
     "duration": 6558.531687,
     "end_time": "2023-05-06T02:57:02.024848",
     "exception": false,
     "start_time": "2023-05-06T01:07:43.493161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = get_model(params['num_classes'], device, model_name='resnet18') # resnet18, resnet34, resnet50, resnet101, densenet121, inception_v3\n",
    "\n",
    "trained_model, history = train_model(model, train_loader, val_loader, device= device, params= params, debug= Hyperparameters._DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37850d75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T02:57:05.260469Z",
     "iopub.status.busy": "2023-05-06T02:57:05.260141Z",
     "iopub.status.idle": "2023-05-06T02:57:05.911381Z",
     "shell.execute_reply": "2023-05-06T02:57:05.910350Z"
    },
    "papermill": {
     "duration": 1.508008,
     "end_time": "2023-05-06T02:57:05.913578",
     "exception": false,
     "start_time": "2023-05-06T02:57:04.405570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493efc3a",
   "metadata": {
    "papermill": {
     "duration": 0.850983,
     "end_time": "2023-05-06T02:57:07.531266",
     "exception": false,
     "start_time": "2023-05-06T02:57:06.680283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95eb4b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T02:57:09.236524Z",
     "iopub.status.busy": "2023-05-06T02:57:09.236162Z",
     "iopub.status.idle": "2023-05-06T02:57:28.113359Z",
     "shell.execute_reply": "2023-05-06T02:57:28.111407Z"
    },
    "papermill": {
     "duration": 19.833132,
     "end_time": "2023-05-06T02:57:28.115668",
     "exception": false,
     "start_time": "2023-05-06T02:57:08.282536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "test_loss, test_acc, test_cm = evaluate_model(trained_model, test_loader, criterion, device)\n",
    "print(\"-\"*45)\n",
    "print(f\"| Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f} |\")\n",
    "print(\"-\"*45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc33a88e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T02:57:29.658129Z",
     "iopub.status.busy": "2023-05-06T02:57:29.657697Z",
     "iopub.status.idle": "2023-05-06T02:57:29.665039Z",
     "shell.execute_reply": "2023-05-06T02:57:29.664007Z"
    },
    "papermill": {
     "duration": 0.779758,
     "end_time": "2023-05-06T02:57:29.667068",
     "exception": false,
     "start_time": "2023-05-06T02:57:28.887310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_matrix, title=\"\"):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    im = ax.matshow(confusion_matrix, cmap=plt.cm.Blues, alpha=0.6)\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        for j in range(confusion_matrix.shape[1]):\n",
    "            ax.text(\n",
    "                x=j, y=i, s=int(confusion_matrix[i, j]), va='center', ha='center')\n",
    "\n",
    "    plt.xlabel('Predictions', fontsize=12)\n",
    "    plt.ylabel('Labels', fontsize=12)\n",
    "    plt.title(f'Confusion Matrix {title}', y= 1.08,  fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9041f2e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T02:57:31.399295Z",
     "iopub.status.busy": "2023-05-06T02:57:31.398916Z",
     "iopub.status.idle": "2023-05-06T02:57:31.849606Z",
     "shell.execute_reply": "2023-05-06T02:57:31.848587Z"
    },
    "papermill": {
     "duration": 1.346622,
     "end_time": "2023-05-06T02:57:31.851802",
     "exception": false,
     "start_time": "2023-05-06T02:57:30.505180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdbd06d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T02:57:33.503811Z",
     "iopub.status.busy": "2023-05-06T02:57:33.503437Z",
     "iopub.status.idle": "2023-05-06T02:57:33.514972Z",
     "shell.execute_reply": "2023-05-06T02:57:33.513952Z"
    },
    "papermill": {
     "duration": 0.78808,
     "end_time": "2023-05-06T02:57:33.517213",
     "exception": false,
     "start_time": "2023-05-06T02:57:32.729133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_roc(model, dataloader, device, cls=0):\n",
    "    emotions = {\n",
    "        0: 'Angry',\n",
    "        1: 'Disgust',\n",
    "        2: 'Fear',\n",
    "        3: 'Happy',\n",
    "        4: 'Sad',\n",
    "        5: 'Surprise',\n",
    "        6: 'Neutral'\n",
    "    }\n",
    "    labels = []\n",
    "    predicted = []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for img, lbl in dataloader:\n",
    "        img, lbl = img.to(device), lbl.to(device)\n",
    "        output = model(img)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "        lbl = lbl.cpu().numpy()\n",
    "        lbl = np.where(lbl == cls, 1, 0)\n",
    "        pred = pred.cpu().numpy()\n",
    "        labels.extend(lbl)\n",
    "        predicted.extend(pred)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(labels, predicted)\n",
    "    roc_auc = roc_auc_score(labels, predicted)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k-')\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title(f'ROC Curve: {emotions[cls]} vs Others', fontsize=16)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa39466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T02:57:35.179310Z",
     "iopub.status.busy": "2023-05-06T02:57:35.178681Z",
     "iopub.status.idle": "2023-05-06T02:57:54.202078Z",
     "shell.execute_reply": "2023-05-06T02:57:54.201024Z"
    },
    "papermill": {
     "duration": 19.84088,
     "end_time": "2023-05-06T02:57:54.204126",
     "exception": false,
     "start_time": "2023-05-06T02:57:34.363246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_roc(trained_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc9ff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T02:57:55.818341Z",
     "iopub.status.busy": "2023-05-06T02:57:55.817944Z",
     "iopub.status.idle": "2023-05-06T02:58:14.328131Z",
     "shell.execute_reply": "2023-05-06T02:58:14.327100Z"
    },
    "papermill": {
     "duration": 19.268244,
     "end_time": "2023-05-06T02:58:14.330380",
     "exception": false,
     "start_time": "2023-05-06T02:57:55.062136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_roc(trained_model, test_loader, device, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff3dec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T02:58:16.076659Z",
     "iopub.status.busy": "2023-05-06T02:58:16.076297Z",
     "iopub.status.idle": "2023-05-06T02:58:16.088549Z",
     "shell.execute_reply": "2023-05-06T02:58:16.087561Z"
    },
    "papermill": {
     "duration": 0.863494,
     "end_time": "2023-05-06T02:58:16.090657",
     "exception": false,
     "start_time": "2023-05-06T02:58:15.227163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# predict for a given image\n",
    "\n",
    "\n",
    "def predict(model, dataloader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    emotions = {\n",
    "        0: 'Angry',\n",
    "        1: 'Disgust',\n",
    "        2: 'Fear',\n",
    "        3: 'Happy',\n",
    "        4: 'Sad',\n",
    "        5: 'Surprise',\n",
    "        6: 'Neutral'\n",
    "    }\n",
    "    # take the first 10 images and plot them with predicted and actual labels\n",
    "    images = []\n",
    "    labels = []\n",
    "    predicted = []\n",
    "    \n",
    "    for image, label in dataloader:\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        output = model(image)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "        for i in range(len(pred)):\n",
    "            images.append(image[i].cpu().numpy())\n",
    "            labels.append(label[i].cpu().numpy())\n",
    "            predicted.append(pred[i].cpu().numpy())\n",
    "        break\n",
    "    \n",
    "    # choose 10 random images\n",
    "    idx = np.random.choice(len(images), 10)\n",
    "    images = np.array(images)[idx]\n",
    "    labels = np.array(labels)[idx]\n",
    "    predicted = np.array(predicted)[idx]\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 5, figsize=(16, 8))\n",
    "    for i in range(2):\n",
    "        for j in range(5):\n",
    "            ax[i, j].imshow(images[i*5+j][0], cmap='gray')\n",
    "            ax[i, j].set_title(f\"Predicted: {emotions[predicted[i*5+j]]}\\nLabel: {emotions[labels[i*5+j]]}\", fontsize=12)\n",
    "            ax[i, j].axis('off')\n",
    "    plt.suptitle('Predictions', y=0.95, fontsize=20)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e9321c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T02:58:18.149718Z",
     "iopub.status.busy": "2023-05-06T02:58:18.148649Z",
     "iopub.status.idle": "2023-05-06T02:58:19.807260Z",
     "shell.execute_reply": "2023-05-06T02:58:19.806038Z"
    },
    "papermill": {
     "duration": 2.945046,
     "end_time": "2023-05-06T02:58:19.809672",
     "exception": false,
     "start_time": "2023-05-06T02:58:16.864626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict(trained_model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6705.554371,
   "end_time": "2023-05-06T02:58:23.573902",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-06T01:06:38.019531",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
